{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Project - Handwritten Digit Recognition using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handwritten Digit Recognition is the ability of computers to recognize human handwritten digits. It is easy for humans to recognize handwritten digits but a hard task for computers since the digit can be made in different flavours. In this notebook a recogniton model would be built with MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the libraries and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#The shape of training data is (60000, 28, 28) but CNN required one more dimension\n",
    "#So we will reshape the data to (60000, 28, 28, 1)\n",
    "#And we also reshape the test data\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change Data type and normalize x_train and x_test\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Turn y_train and y_test data to a binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create model\n",
    "Now we will create a CNN Model. A CNN Model usually consists of convoluational and pooling layers, followed by dropout and fully connected layers. The dropout layers are used to deactive some of the neurons to aviod over fitting. We will then compile the modle with the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "input_shape = (28,28,1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape = input_shape))\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = tf.keras.losses.categorical_crossentropy, optimizer = tf.keras.optimizers.Adam(), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 188s 398ms/step - loss: 0.1751 - accuracy: 0.9468 - val_loss: 0.0449 - val_accuracy: 0.9850\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 195s 416ms/step - loss: 0.0529 - accuracy: 0.9839 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 232s 495ms/step - loss: 0.0371 - accuracy: 0.9881 - val_loss: 0.0326 - val_accuracy: 0.9891\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 277s 591ms/step - loss: 0.0290 - accuracy: 0.9904 - val_loss: 0.0265 - val_accuracy: 0.9913\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 317s 675ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.0279 - val_accuracy: 0.9899\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 306s 652ms/step - loss: 0.0188 - accuracy: 0.9938 - val_loss: 0.0317 - val_accuracy: 0.9902\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 313s 668ms/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.0281 - val_accuracy: 0.9915\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 301s 641ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.0325 - val_accuracy: 0.9895\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 360s 768ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0285 - val_accuracy: 0.9913\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 355s 756ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.0300 - val_accuracy: 0.9919\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, verbose = 1, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.029978826642036438\n",
      "Test accuracy: 0.9919000267982483\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
